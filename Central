churn_output_std = churn_output[['dealer_code', 'churn_risk_score', 'notification']].copy()
churn_output_std['score'] = churn_output_std['churn_risk_score']
churn_output_std['insight_type'] = 'Churn'
churn_output_std = churn_output_std[['dealer_code', 'insight_type', 'score', 'notification']]



od_output_std = od_output[['dealer_code', 'od_risk_score', 'notification']].copy()
od_output_std['score'] = od_output_std['od_risk_score']
od_output_std['insight_type'] = 'OD Risk'
od_output_std = od_output_std[['dealer_code', 'insight_type', 'score', 'notification']]



engagement_output_std = engagement_output[['dealer_code', 'product_category', 'drop_prob', 'notification']].copy()
engagement_output_std['score'] = engagement_output_std['drop_prob']
engagement_output_std['insight_type'] = 'Engagement Drop'
engagement_output_std = engagement_output_std[['dealer_code', 'insight_type', 'product_category', 'score', 'notification']]


adv_push_std = adv_push_output[['dealer_code', 'target_push_potential']].copy()
adv_push_std['score'] = adv_push_std['target_push_potential'] * 1.0
adv_push_std['notification'] = adv_push_std['dealer_code'].apply(
    lambda x: f"Dealer {x} is a candidate for push based on advanced product uptake.")
adv_push_std['insight_type'] = 'Advanced Push Potential'
adv_push_std = adv_push_std[['dealer_code', 'insight_type', 'score', 'notification']]


adv_drop_std = adv_drop_output[adv_drop_output['drop_flag'] == 1].copy()
adv_drop_std['score'] = 1.0
adv_drop_std['notification'] = adv_drop_std['dealer_code'].apply(
    lambda x: f"Dealer {x} shows risk of disengaging from advanced product category.")
adv_drop_std['insight_type'] = 'Advanced Ratio Drop'
adv_drop_std = adv_drop_std[['dealer_code', 'insight_type', 'score', 'notification']]


def compute_drop_score(row):
    early = row['adv_early_slope']
    late = row['adv_late_slope']
    volume = row['volume_slope_last3']

    # Only compute if all drop conditions met
    if early >= 0 and late < 0 and volume >= 0:
        # Sharper drop = higher score
        drop_magnitude = early - late  # e.g. +10 to -20 = 30
        return min(1.0, max(0.3, drop_magnitude / 50))  # scale: 50-unit swing = full score
    else:
        return 0.0

adv_drop_std = adv_drop_df.copy()
adv_drop_std['score'] = adv_drop_std.apply(compute_drop_score, axis=1)
adv_drop_std['insight_type'] = 'Advanced Ratio Drop'
adv_drop_std['notification'] = adv_drop_std['dealer_code'].apply(
    lambda x: f"Dealer {x} shows declining adoption of advanced products despite stable sales."
)
adv_drop_std = adv_drop_std[['dealer_code', 'insight_type', 'score', 'notification']]

def compute_push_score(row):
    adv_slope = row['adv_ratio_slope']
    value_growth = row['value_growth_pct']
    volume_growth = row['volume_growth_pct']

    # Only compute score if target_push_potential is 1
    if row['target_push_potential'] != 1:
        return 0.0

    # Normalize slopes into 0.3–1.0
    slope_score = min(1.0, max(0.3, adv_slope / 100))  # cap at 100

    # Reward if value & volume growth > 0
    growth_bonus = 0
    if value_growth > 0:
        growth_bonus += 0.1
    if volume_growth > 0:
        growth_bonus += 0.1

    final_score = min(1.0, slope_score + growth_bonus)
    return final_score

adv_push_std = adv_push_df.copy()
adv_push_std['score'] = adv_push_std.apply(compute_push_score, axis=1)
adv_push_std['insight_type'] = 'Advanced Push Potential'
adv_push_std['notification'] = adv_push_std['dealer_code'].apply(
    lambda x: f"Dealer {x} is a candidate for push based on advanced product momentum."
)
adv_push_std = adv_push_std[['dealer_code', 'insight_type', 'score', 'notification']]

territory_map = pd.read_csv("territory_mapping.csv")  # Replace with actual path

dealer_insights = pd.concat([
    churn_output_std,    # ['dealer_code', 'insight_type', 'score', 'notification']
    od_output_std,
    adv_push_std,
    adv_drop_std
], ignore_index=True)

# Add territory
dealer_insights = dealer_insights.merge(territory_map, on='dealer_code', how='left')

# Confirm structure
print(dealer_insights.columns)
# Should have: ['dealer_code', 'insight_type', 'score', 'notification', 'territory']

print(dealer_insights['insight_type'].value_counts())
print(dealer_insights['territory'].nunique(), "territories")


import pandas as pd

# STEP 1: Combine Dealer-Level Insights
dealer_insights = pd.concat([
    churn_output_std,
    od_output_std,
    adv_push_std,
    adv_drop_std
], ignore_index=True)

dealer_insights = dealer_insights.merge(territory_map, on='dealer_code', how='left')

# STEP 2: Engagement Drop → Add Territory
engagement_output_std = engagement_output_std.merge(territory_map, on='dealer_code', how='left')

# STEP 3: Calculate Average Scores per Insight Type per Territory
avg_dealer_scores = (
    dealer_insights
    .groupby(['territory', 'insight_type'])['score']
    .mean()
    .reset_index()
)

avg_engagement_score = (
    engagement_output_std
    .groupby(['territory', 'insight_type'])['score']
    .mean()
    .reset_index()
)

avg_scores = pd.concat([avg_dealer_scores, avg_engagement_score], ignore_index=True)

# STEP 4: Apply Business Weights
business_weights = {
    'Churn': 0.35,
    'OD Risk': 0.25,
    'Engagement Drop': 0.20,
    'Advanced Push Potential': 0.10,
    'Advanced Ratio Drop': 0.10
}

avg_scores['weight'] = avg_scores['insight_type'].map(business_weights)
avg_scores['weighted_score'] = avg_scores['score'] * avg_scores['weight']

# === Step 5: Select top 2 insight types per territory ===
avg_scores_sorted = avg_scores.sort_values(['territory', 'weighted_score'], ascending=[True, False])
top2_insights_per_territory = avg_scores_sorted.groupby('territory').head(2).reset_index(drop=True)

from collections import defaultdict
import pandas as pd

# --- Grouping notifications properly across dealers sharing the same 'issue' ---

grouped_notifications = []

for territory in top2_insights_per_territory['territory'].unique():
    grouped_notifications.append(f"=== Territory: {territory} ===\n")

    selected_insights = top2_insights_per_territory[
        top2_insights_per_territory['territory'] == territory
    ]['insight_type'].tolist()

    for insight in selected_insights:
        grouped_notifications.append(f"\n{insight}:\n")

        if insight == 'Engagement Drop':
            df = engagement_output_std[engagement_output_std['territory'] == territory]

            # Get top product category by average score
            top_category = (
                df.groupby('product_category')['score']
                .mean()
                .sort_values(ascending=False)
                .index[0]
            )

            top_df = df[df['product_category'] == top_category]
            dealers = sorted(top_df['dealer_code'].astype(str).unique())

            grouped_notifications.append(
                f"• Dealers {', '.join(dealers)} likely to disengage from {top_category}"
            )

        else:
            df = dealer_insights[
                (dealer_insights['territory'] == territory) &
                (dealer_insights['insight_type'] == insight)
            ][['dealer_code', 'notification']].copy()

            # Step 1: Extract "reason" = trailing message after colon
            df['issue'] = df['notification'].str.split("due to:").str[-1].str.strip().fillna("")

            # Step 2: Group by 'issue'
            issue_groups = df.groupby('issue')['dealer_code'].apply(lambda x: sorted(x.astype(str).unique())).reset_index()

            for _, row in issue_groups.iterrows():
                dealers = row['dealer_code']
                reason = row['issue']

                if insight == 'Advanced Push Potential':
                    grouped_notifications.append(
                        f"• Dealers {', '.join(dealers)} are candidates for push based on advanced product momentum."
                    )
                else:
                    grouped_notifications.append(
                        f"• Dealers {', '.join(dealers)} likely to reduce purchase due to: {reason}"
                    )

# Show final grouped output
final_output = "\n".join(grouped_notifications)
print(final_output)
