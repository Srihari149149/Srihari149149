churn_output_std = churn_output[['dealer_code', 'churn_risk_score', 'notification']].copy()
churn_output_std['score'] = churn_output_std['churn_risk_score']
churn_output_std['insight_type'] = 'Churn'
churn_output_std = churn_output_std[['dealer_code', 'insight_type', 'score', 'notification']]



od_output_std = od_output[['dealer_code', 'od_risk_score', 'notification']].copy()
od_output_std['score'] = od_output_std['od_risk_score']
od_output_std['insight_type'] = 'OD Risk'
od_output_std = od_output_std[['dealer_code', 'insight_type', 'score', 'notification']]



engagement_output_std = engagement_output[['dealer_code', 'product_category', 'drop_prob', 'notification']].copy()
engagement_output_std['score'] = engagement_output_std['drop_prob']
engagement_output_std['insight_type'] = 'Engagement Drop'
engagement_output_std = engagement_output_std[['dealer_code', 'insight_type', 'product_category', 'score', 'notification']]


adv_push_std = adv_push_output[['dealer_code', 'target_push_potential']].copy()
adv_push_std['score'] = adv_push_std['target_push_potential'] * 1.0
adv_push_std['notification'] = adv_push_std['dealer_code'].apply(
    lambda x: f"Dealer {x} is a candidate for push based on advanced product uptake.")
adv_push_std['insight_type'] = 'Advanced Push Potential'
adv_push_std = adv_push_std[['dealer_code', 'insight_type', 'score', 'notification']]


adv_drop_std = adv_drop_output[adv_drop_output['drop_flag'] == 1].copy()
adv_drop_std['score'] = 1.0
adv_drop_std['notification'] = adv_drop_std['dealer_code'].apply(
    lambda x: f"Dealer {x} shows risk of disengaging from advanced product category.")
adv_drop_std['insight_type'] = 'Advanced Ratio Drop'
adv_drop_std = adv_drop_std[['dealer_code', 'insight_type', 'score', 'notification']]


def compute_drop_score(row):
    early = row['adv_early_slope']
    late = row['adv_late_slope']
    volume = row['volume_slope_last3']

    # Only compute if all drop conditions met
    if early >= 0 and late < 0 and volume >= 0:
        # Sharper drop = higher score
        drop_magnitude = early - late  # e.g. +10 to -20 = 30
        return min(1.0, max(0.3, drop_magnitude / 50))  # scale: 50-unit swing = full score
    else:
        return 0.0

adv_drop_std = adv_drop_df.copy()
adv_drop_std['score'] = adv_drop_std.apply(compute_drop_score, axis=1)
adv_drop_std['insight_type'] = 'Advanced Ratio Drop'
adv_drop_std['notification'] = adv_drop_std['dealer_code'].apply(
    lambda x: f"Dealer {x} shows declining adoption of advanced products despite stable sales."
)
adv_drop_std = adv_drop_std[['dealer_code', 'insight_type', 'score', 'notification']]

def compute_push_score(row):
    adv_slope = row['adv_ratio_slope']
    value_growth = row['value_growth_pct']
    volume_growth = row['volume_growth_pct']

    # Only compute score if target_push_potential is 1
    if row['target_push_potential'] != 1:
        return 0.0

    # Normalize slopes into 0.3–1.0
    slope_score = min(1.0, max(0.3, adv_slope / 100))  # cap at 100

    # Reward if value & volume growth > 0
    growth_bonus = 0
    if value_growth > 0:
        growth_bonus += 0.1
    if volume_growth > 0:
        growth_bonus += 0.1

    final_score = min(1.0, slope_score + growth_bonus)
    return final_score

adv_push_std = adv_push_df.copy()
adv_push_std['score'] = adv_push_std.apply(compute_push_score, axis=1)
adv_push_std['insight_type'] = 'Advanced Push Potential'
adv_push_std['notification'] = adv_push_std['dealer_code'].apply(
    lambda x: f"Dealer {x} is a candidate for push based on advanced product momentum."
)
adv_push_std = adv_push_std[['dealer_code', 'insight_type', 'score', 'notification']]

territory_map = pd.read_csv("territory_mapping.csv")  # Replace with actual path

dealer_insights = pd.concat([
    churn_output_std,    # ['dealer_code', 'insight_type', 'score', 'notification']
    od_output_std,
    adv_push_std,
    adv_drop_std
], ignore_index=True)

# Add territory
dealer_insights = dealer_insights.merge(territory_map, on='dealer_code', how='left')

# Confirm structure
print(dealer_insights.columns)
# Should have: ['dealer_code', 'insight_type', 'score', 'notification', 'territory']

print(dealer_insights['insight_type'].value_counts())
print(dealer_insights['territory'].nunique(), "territories")


import pandas as pd

# STEP 1: Combine Dealer-Level Insights
dealer_insights = pd.concat([
    churn_output_std,
    od_output_std,
    adv_push_std,
    adv_drop_std
], ignore_index=True)

dealer_insights = dealer_insights.merge(territory_map, on='dealer_code', how='left')

# STEP 2: Engagement Drop → Add Territory
engagement_output_std = engagement_output_std.merge(territory_map, on='dealer_code', how='left')

# STEP 3: Calculate Average Scores per Insight Type per Territory
avg_dealer_scores = (
    dealer_insights
    .groupby(['territory', 'insight_type'])['score']
    .mean()
    .reset_index()
)

avg_engagement_score = (
    engagement_output_std
    .groupby(['territory', 'insight_type'])['score']
    .mean()
    .reset_index()
)

avg_scores = pd.concat([avg_dealer_scores, avg_engagement_score], ignore_index=True)

# STEP 4: Apply Business Weights
business_weights = {
    'Churn': 0.35,
    'OD Risk': 0.25,
    'Engagement Drop': 0.20,
    'Advanced Push Potential': 0.10,
    'Advanced Ratio Drop': 0.10
}

avg_scores['weight'] = avg_scores['insight_type'].map(business_weights)
avg_scores['weighted_score'] = avg_scores['score'] * avg_scores['weight']

import pandas as pd

# === STEP 1: Merge territory into all insight DataFrames ===
dealer_insights = pd.concat([
    churn_output_std,
    od_output_std,
    adv_push_std,
    adv_drop_std
], ignore_index=True)

dealer_insights = dealer_insights.merge(territory_map, on='dealer_code', how='left')
engagement_output_std = engagement_output_std.merge(territory_map, on='dealer_code', how='left')

# === STEP 2: Calculate territory-level average scores ===
avg_dealer_scores = dealer_insights.groupby(['territory', 'insight_type'])['score'].mean().reset_index()
avg_engagement_scores = engagement_output_std.groupby(['territory', 'insight_type'])['score'].mean().reset_index()
avg_scores = pd.concat([avg_dealer_scores, avg_engagement_scores], ignore_index=True)

# === STEP 3: Apply business weights and calculate weighted score ===
business_weights = {
    'Churn': 0.35,
    'OD Risk': 0.25,
    'Engagement Drop': 0.20,
    'Advanced Push Potential': 0.10,
    'Advanced Ratio Drop': 0.10
}
avg_scores['weight'] = avg_scores['insight_type'].map(business_weights)
avg_scores['weighted_score'] = avg_scores['score'] * avg_scores['weight']

# === STEP 4: Pick top 2 insights per territory ===
top2_insights_per_territory = (
    avg_scores.sort_values(['territory', 'weighted_score'], ascending=[True, False])
    .groupby('territory')
    .head(2)
    .reset_index(drop=True)
)

# === STEP 5: Generate grouped notifications as rows ===
rows = []

for territory in top2_insights_per_territory['territory'].unique():
    selected_insights = top2_insights_per_territory[
        top2_insights_per_territory['territory'] == territory
    ]['insight_type'].tolist()

    for insight in selected_insights:
        if insight == 'Engagement Drop':
            df = engagement_output_std[engagement_output_std['territory'] == territory]

            top_category_row = (
                df.groupby('product_category')['score']
                .mean()
                .reset_index()
                .sort_values('score', ascending=False)
            )

            if not top_category_row.empty:
                top_category = top_category_row.iloc[0]['product_category']
                dealers = sorted(
                    df[df['product_category'] == top_category]['dealer_code'].astype(str).unique()
                )
                rows.append({
                    'territory': territory,
                    'insight_type': insight,
                    'notification': f"Dealers {', '.join(dealers)} likely to disengage from {top_category}"
                })
        else:
            df = dealer_insights[
                (dealer_insights['territory'] == territory) &
                (dealer_insights['insight_type'] == insight)
            ][['dealer_code', 'notification']].copy()

            df['issue'] = df['notification'].str.split("due to:").str[-1].str.strip().fillna("")

            grouped = df.groupby('issue')['dealer_code'].apply(
                lambda x: sorted(x.astype(str).unique())
            ).reset_index()

            for _, row in grouped.iterrows():
                issue = row['issue']
                dealers = row['dealer_code']

                if insight == 'Advanced Push Potential':
                    notif = f"Dealers {', '.join(dealers)} are candidates for push based on advanced product momentum."
                else:
                    notif = f"Dealers {', '.join(dealers)} likely to reduce purchase due to: {issue}"

                rows.append({
                    'territory': territory,
                    'insight_type': insight,
                    'notification': notif
                })

# === STEP 6: Create final table with top 2 grouped notifications per territory ===
notification_df = pd.DataFrame(rows)
notification_df['rank'] = notification_df.groupby('territory').cumcount() + 1
final_notification_table = notification_df[notification_df['rank'] <= 2].drop(columns='rank')

# === Display final structured output ===
import ace_tools as tools
tools.display_dataframe_to_user(name="Top 2 Grouped Notifications per Territory", dataframe=final_notification_table)

