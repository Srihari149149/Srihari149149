import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# File paths
sales_file = r"C:\Users\P00993489\Downloads\GOmumbai.csv"
value_audit_file1 = r"C:\Users\P00993489\Downloads\Value_Audit.csv"
value_audit_file2 = r"C:\Users\P00993489\Downloads\Value_audit_2.csv"
od_data_path = r"C:\Users\P00993489\Downloads\OD_Data.xlsx"  # Path to OD data Excel workbook

# Define column names
sales_cols = ['Date', 'value', 'volume', 'territory', 'dealer code', 'category']  # Added category
audit_cols = ['Competitor__r.Name', 'Dealer__r.Account_Code__c', 'Dealer__r.Name', 'Value__c', 'Category__c']  # Added category

# Load and preprocess sales data
print("Loading sales data...")
sales_df = pd.read_csv(sales_file, usecols=sales_cols, encoding='latin1')
sales_df["date"] = pd.to_datetime(sales_df["Date"])
sales_df["month"] = sales_df["date"].dt.to_period("M").dt.to_timestamp()
sales_df["year"] = sales_df["date"].dt.year
sales_df["month_num"] = sales_df["date"].dt.month
sales_df['month_ordinal'] = sales_df['month'].map(lambda x: x.toordinal())

# Standardize dealer codes
sales_df['dealer_code'] = sales_df['dealer code'].astype(str).str[-6:]
sales_df = sales_df[~sales_df['dealer_code'].str.startswith('INB', na=False)]

print("Sales data shape:", sales_df.shape)


 Load and preprocess competitor data (Value Audit)
print("Loading competitor data...")
value_audit_df1 = pd.read_csv(value_audit_file1, usecols=audit_cols)
value_audit_df2 = pd.read_csv(value_audit_file2, usecols=audit_cols)

# Filter out 'APL' competitors and standardize dealer codes
value_audit_2024 = value_audit_df1[value_audit_df1['Competitor__r.Name'] != 'APL']
value_audit_2023 = value_audit_df2[value_audit_df2['Competitor__r.Name'] != 'APL']

value_audit_2024['dealer_code'] = value_audit_2024['Dealer__r.Account_Code__c'].astype(str).str[-6:]
value_audit_2023['dealer_code'] = value_audit_2023['Dealer__r.Account_Code__c'].astype(str).str[-6:]

print("Competitor data shapes:", value_audit_2024.shape, value_audit_2023.shape)

 Load OD (Overdue) data from Excel with multiple sheets
# -------------------------------
# Load OD (Overdue) data from Excel with multiple sheets
# -------------------------------
print("Loading OD data...")
od_monthly_df = pd.DataFrame()

try:
    # Load the Excel file
    excel_file = pd.ExcelFile(od_data_path)
    sheet_names = excel_file.sheet_names
    all_sheets_data = []

    for sheet in sheet_names:
        try:
            # Read each sheet
            temp_df = pd.read_excel(excel_file, sheet_name=sheet)

            # Required columns
            required_cols = ['Posting Date', 'Customer', 'Net Over Due']
            if all(col in temp_df.columns for col in required_cols):
                # Select and rename
                sheet_data = temp_df[required_cols].copy()
                sheet_data.columns = ['posting_date', 'customer', 'overdue_amount']

                # Convert date and extract month
                sheet_data['posting_date'] = pd.to_datetime(sheet_data['posting_date'], errors='coerce')
                sheet_data = sheet_data.dropna(subset=['posting_date'])
                sheet_data['month'] = sheet_data['posting_date'].dt.to_period('M').dt.to_timestamp()

                # Extract last 6 digits of dealer code
                sheet_data['dealer_code'] = sheet_data['customer'].astype(str).str.extract(r'(\d{6})')
                sheet_data = sheet_data.dropna(subset=['dealer_code'])
                sheet_data['dealer_code'] = sheet_data['dealer_code'].astype(str)

                # Keep only needed columns
                all_sheets_data.append(sheet_data[['dealer_code', 'month', 'overdue_amount']])
            else:
                print(f"Sheet {sheet} missing required columns. Skipping.")
        except Exception as e:
            print(f"Error processing sheet {sheet}: {e}")

    # Combine all sheets
    if all_sheets_data:
        od_monthly_df = pd.concat(all_sheets_data, ignore_index=True)
        od_monthly_df = od_monthly_df.sort_values(['dealer_code', 'month'])
        print("OD data shape:", od_monthly_df.shape)
    else:
        print("No valid OD data found in any sheet.")
        od_monthly_df = pd.DataFrame(columns=['dealer_code', 'month', 'overdue_amount'])

except Exception as e:
    print(f"Error loading OD data: {e}")
    print("Proceeding without OD data...")
    od_monthly_df = pd.DataFrame(columns=['dealer_code', 'month', 'overdue_amount'])


print("Calculating competitor YoY growth...")

# Group and sum total competitor value per dealer and category
agg_2024 = value_audit_2024.groupby(['dealer_code', 'Category__c'])['Value__c'].sum().reset_index().rename(
    columns={'Value__c': 'comp_value_2024', 'Category__c': 'category'})
agg_2023 = value_audit_2023.groupby(['dealer_code', 'Category__c'])['Value__c'].sum().reset_index().rename(
    columns={'Value__c': 'comp_value_2023', 'Category__c': 'category'})

# Overall dealer totals
dealer_total_2024 = value_audit_2024.groupby('dealer_code')['Value__c'].sum().reset_index().rename(
    columns={'Value__c': 'comp_value_2024'})
dealer_total_2023 = value_audit_2023.groupby('dealer_code')['Value__c'].sum().reset_index().rename(
    columns={'Value__c': 'comp_value_2023'})

# Merge and calculate YoY
category_yoy = pd.merge(agg_2024, agg_2023, on=['dealer_code', 'category'], how='left')
category_yoy = category_yoy.dropna(subset=['comp_value_2023'])
category_yoy['comp_yoy_growth'] = ((category_yoy['comp_value_2024'] - category_yoy['comp_value_2023']) / category_yoy['comp_value_2023'])

dealer_yoy = pd.merge(dealer_total_2024, dealer_total_2023, on='dealer_code', how='left')
dealer_yoy = dealer_yoy.dropna(subset=['comp_value_2023'])
dealer_yoy['comp_yoy_growth'] = ((dealer_yoy['comp_value_2024'] - dealer_yoy['comp_value_2023']) / dealer_yoy['comp_value_2023'])

# Clean up
category_yoy = category_yoy.replace([np.inf, -np.inf], np.nan).dropna(subset=['comp_yoy_growth'])
dealer_yoy = dealer_yoy.replace([np.inf, -np.inf], np.nan).dropna(subset=['comp_yoy_growth'])

print("Competitor YoY growth calculated.")

print("Analyzing sales data trends...")

# Helper functions
def compute_slope(group):
    if len(group) < 2:
        return np.nan
    X = group['month_ordinal'].values.reshape(-1, 1)
    y = group['value'].values
    model = LinearRegression()
    model.fit(X, y)
    return model.coef_[0]

def compute_volume_slope(group):
    if len(group) < 2:
        return np.nan
    X = group['month_ordinal'].values.reshape(-1, 1)
    y = group['volume'].values
    model = LinearRegression()
    model.fit(X, y)
    return model.coef_[0]

# Most recent 3 months
recent_months = sorted(sales_df['month'].unique())[-3:]
sales_3m = sales_df[sales_df['month'].isin(recent_months)]
# Group by dealer and category
cat_region_3m = sales_3m.groupby(['dealer_code', 'category'])['value'].sum().reset_index(name='3m_value')

# Add placeholder for 'region_growth' using global_growth_slope (since entire dataset is one region)
cat_region_3m['region_growth'] = global_growth_slope

# Dealer-level trend
dealer_trends = sales_3m.groupby('dealer_code').apply(compute_slope).reset_index(name='sales_slope')
dealer_volume_trends = sales_3m.groupby('dealer_code').apply(compute_volume_slope).reset_index(name='volume_slope')
dealer_trends = pd.merge(dealer_trends, dealer_volume_trends, on='dealer_code', how='left')

# Category-level trend
category_trends = sales_3m.groupby(['dealer_code', 'category']).apply(compute_slope).reset_index(name='sales_slope')
category_volume_trends = sales_3m.groupby(['dealer_code', 'category']).apply(compute_volume_slope).reset_index(name='volume_slope')
category_trends = pd.merge(category_trends, category_volume_trends, on=['dealer_code', 'category'], how='left')

# YoY Sales Growth
current_year = sales_df['year'].max()
prev_year = current_year - 1

dealer_sales_current = sales_df[sales_df['year'] == current_year].groupby('dealer_code')['value'].sum().reset_index(name='current_sales')
dealer_sales_prev = sales_df[sales_df['year'] == prev_year].groupby('dealer_code')['value'].sum().reset_index(name='prev_sales')
dealer_sales_yoy = pd.merge(dealer_sales_current, dealer_sales_prev, on='dealer_code', how='left')
dealer_sales_yoy['sales_yoy_growth'] = ((dealer_sales_yoy['current_sales'] - dealer_sales_yoy['prev_sales']) / dealer_sales_yoy['prev_sales'])
dealer_sales_yoy = dealer_sales_yoy.replace([np.inf, -np.inf], np.nan).dropna(subset=['sales_yoy_growth'])

# Category-level YoY
cat_sales_current = sales_df[sales_df['year'] == current_year].groupby(['dealer_code', 'category'])['value'].sum().reset_index(name='current_sales')
cat_sales_prev = sales_df[sales_df['year'] == prev_year].groupby(['dealer_code', 'category'])['value'].sum().reset_index(name='prev_sales')
cat_sales_yoy = pd.merge(cat_sales_current, cat_sales_prev, on=['dealer_code', 'category'], how='left')
cat_sales_yoy['sales_yoy_growth'] = ((cat_sales_yoy['current_sales'] - cat_sales_yoy['prev_sales']) / cat_sales_yoy['prev_sales'])
cat_sales_yoy = cat_sales_yoy.replace([np.inf, -np.inf], np.nan).dropna(subset=['sales_yoy_growth'])

print("Sales trends calculated.")

print("Calculating global 3-month growth trend (entire division)...")

# ✅ Step 1: Get last 3 months
recent_months = sorted(sales_df['month'].unique())[-3:]
sales_3m = sales_df[sales_df['month'].isin(recent_months)]

# ✅ Step 2: Aggregate total value by month
monthly_sales = sales_3m.groupby('month')['value'].sum().reset_index()
monthly_sales['month_index'] = range(len(monthly_sales))

# ✅ Step 3: Apply linear regression to get overall trend
X = monthly_sales['month_index'].values.reshape(-1, 1)
y = monthly_sales['value'].values
model = LinearRegression()
model.fit(X, y)
global_growth_slope = model.coef_[0]

print(f"Overall 3-month growth slope: {global_growth_slope:.2f}")

# -------------------------------
# Feature 4: OD Data Analysis
# -------------------------------
print("Analyzing overdue payment patterns...")

if not od_monthly_df.empty:
    # ✅ Step 1: Get 6 most recent months
    recent_od_months = sorted(od_monthly_df['month'].unique())[-6:]
    recent_od_data = od_monthly_df[od_monthly_df['month'].isin(recent_od_months)]

    # ✅ Step 2: Average OD per dealer
    od_avg = recent_od_data.groupby('dealer_code')['overdue_amount'].mean().reset_index(name='avg_od_amount')

    # ✅ Step 3: OD slope using linear regression
    def compute_od_slope(group):
        if len(group) < 2:
            return np.nan
        X = group['month'].map(lambda x: x.toordinal()).values.reshape(-1, 1)
        y = group['overdue_amount'].values
        model = LinearRegression()
        model.fit(X, y)
        return model.coef_[0]

    od_trend = recent_od_data.groupby('dealer_code').apply(compute_od_slope).reset_index(name='od_slope')

    # ✅ Step 4: Persistence = how many months dealer had OD
    od_persistence = recent_od_data.groupby('dealer_code').size().reset_index(name='od_persistence')
    od_persistence['od_persistence_ratio'] = od_persistence['od_persistence'] / len(recent_od_months)

    # ✅ Step 5: Merge all OD metrics
    od_analysis = pd.merge(od_avg, od_trend, on='dealer_code', how='left')
    od_analysis = pd.merge(od_analysis, od_persistence[['dealer_code', 'od_persistence_ratio']], on='dealer_code', how='left')

    print("OD analysis completed.")

else:
    print("No OD data available. Creating empty DataFrame.")
    od_analysis = pd.DataFrame(columns=['dealer_code', 'avg_od_amount', 'od_slope', 'od_persistence_ratio'])

print("Calculating dealer-level churn risk scores...")

# ✅ Merge all dealer-level features
dealer_features = dealer_trends.copy()

dealer_features = pd.merge(dealer_features, dealer_yoy[['dealer_code', 'comp_yoy_growth']], on='dealer_code', how='left')
dealer_features = pd.merge(dealer_features, dealer_sales_yoy[['dealer_code', 'sales_yoy_growth']], on='dealer_code', how='left')

# Add global slope as column (so we can use same function)
dealer_features['global_growth_slope'] = global_growth_slope

# Add OD data
if not od_analysis.empty:
    dealer_features = pd.merge(dealer_features, od_analysis, on='dealer_code', how='left')
else:
    dealer_features['avg_od_amount'] = 0
    dealer_features['od_slope'] = 0
    dealer_features['od_persistence_ratio'] = 0

# -------------------------------
# Risk Scaling Functions
# -------------------------------
def scale_sales_slope(val):
    if pd.isna(val): return 0.5
    return 0.5 + min(0.5, abs(val) / 100) if val < 0 else 0.5 - min(0.5, val / 100)

def scale_comp_growth(val):
    if pd.isna(val): return 0.5
    return 0.5 + min(0.5, val / 2) if val > 0 else 0.5 - min(0.5, abs(val) / 2)

def scale_sales_yoy(val):
    if pd.isna(val): return 0.5
    return 0.5 + min(0.5, abs(val)) if val < 0 else 0.5 - min(0.5, val)

def scale_regional_growth(dealer_val, global_val):
    if pd.isna(dealer_val) or pd.isna(global_val): return 0.5
    if global_val > 0 and dealer_val < 0: return 0.75
    elif global_val < 0 and dealer_val < global_val: return 0.9
    elif global_val < 0 and dealer_val > global_val: return 0.3
    elif global_val > 0 and dealer_val > global_val: return 0.1
    else: return 0.5

# Scale first (allow some NaNs)
dealer_features['retail_audit_risk'] = dealer_features['comp_yoy_growth'].apply(scale_comp_growth)
dealer_features['sales_yoy_risk'] = dealer_features['sales_yoy_growth'].apply(scale_sales_yoy)
dealer_features['sales_trend_risk'] = dealer_features['sales_slope'].apply(scale_sales_slope)
dealer_features['regional_risk'] = dealer_features.apply(
    lambda x: scale_regional_growth(x['sales_slope'], x['global_growth_slope']), axis=1)
dealer_features['od_risk'] = dealer_features.apply(
    lambda x: scale_od_risk(x['avg_od_amount'], x['od_slope'], x['od_persistence_ratio']), axis=1)

# Filter: skip dealers with 0 for key sales-related risks
filtered_dealer_features = dealer_features[
    (dealer_features['sales_yoy_risk'] != 0) &
    (dealer_features['sales_trend_risk'] != 0) &
    (dealer_features['regional_risk'] != 0)
].copy()


# -------------------------------
# Apply Scaling
# -------------------------------
dealer_features['retail_audit_risk'] = dealer_features['comp_yoy_growth'].apply(scale_comp_growth)
dealer_features['sales_yoy_risk'] = dealer_features['sales_yoy_growth'].apply(scale_sales_yoy)
dealer_features['sales_trend_risk'] = dealer_features['sales_slope'].apply(scale_sales_slope)
dealer_features['od_risk'] = dealer_features.apply(
    lambda x: scale_od_risk(x['avg_od_amount'], x['od_slope'], x['od_persistence_ratio']), axis=1)
dealer_features['regional_risk'] = dealer_features.apply(
    lambda x: scale_regional_growth(x['sales_slope'], x['global_growth_slope']), axis=1)

# -------------------------------
# Final Risk Score and Flag
# -------------------------------
# Compute weighted churn score with OD risk optional
dealer_features['churn_risk_score'] = (
    dealer_features['retail_audit_risk'] * 0.20 +
    dealer_features['sales_yoy_risk'] * 0.10 +
    dealer_features['sales_trend_risk'] * 0.25 +
    dealer_features['regional_risk'] * 0.25 +
    dealer_features['od_risk'].fillna(0) * 0.20  # if OD is NaN, it contributes 0 risk
)


# Flag churn risk if score >= threshold
risk_threshold = 0.65
dealer_features['churn_risk_flag'] = (dealer_features['churn_risk_score'] >= risk_threshold).astype(int)

# -------------------------------
# Notifications
# -------------------------------
dealer_features['notification'] = ''
high_risk_dealers = dealer_features[dealer_features['churn_risk_flag'] == 1]

for idx, row in high_risk_dealers.iterrows():
    factors = []
    if row['retail_audit_risk'] > 0.7:
        factors.append(f"rising competitor sales (+{row['comp_yoy_growth']*100:.1f}%)")
    if row['sales_yoy_risk'] > 0.7:
        factors.append(f"declining YoY sales ({row['sales_yoy_growth']*100:.1f}%)")
    if row['sales_trend_risk'] > 0.7:
        factors.append("negative 3-month sales trend")
    if row['regional_risk'] > 0.7:
        factors.append("underperforming vs overall trend")
    if row['od_risk'] > 0.7:
        factors.append("persistent overdue payments")
    
    if factors:
        dealer_features.at[idx, 'notification'] = (
            f"Dealer {row['dealer_code']} shows high churn risk due to: {', '.join(factors)}."
        )

print("Dealer-level churn scoring complete.")

print("Calculating category-level churn risk scores...")

# ✅ Start with trend features
category_features = category_trends.copy()

# Merge all required features
category_features = pd.merge(category_features, category_yoy[['dealer_code', 'category', 'comp_yoy_growth']],
                             on=['dealer_code', 'category'], how='left')
category_features = pd.merge(category_features, cat_sales_yoy[['dealer_code', 'category', 'sales_yoy_growth']],
                             on=['dealer_code', 'category'], how='left')
category_features = pd.merge(category_features, cat_region_3m[['dealer_code', 'category', 'region_growth']],
                             on=['dealer_code', 'category'], how='left')

# Add global_growth_slope as baseline (entire division)
category_features['global_growth_slope'] = global_growth_slope

# Merge OD data (same across all categories for a dealer)
if not od_analysis.empty:
    category_features = pd.merge(category_features, od_analysis, on='dealer_code', how='left')
else:
    category_features['avg_od_amount'] = 0
    category_features['od_slope'] = 0
    category_features['od_persistence_ratio'] = 0

# ✅ Apply scaling functions
category_features['retail_audit_risk'] = category_features['comp_yoy_growth'].apply(scale_comp_growth)
category_features['sales_yoy_risk'] = category_features['sales_yoy_growth'].apply(scale_sales_yoy)
category_features['sales_trend_risk'] = category_features['sales_slope'].apply(scale_sales_slope)
category_features['regional_risk'] = category_features.apply(
    lambda x: scale_regional_growth(x['sales_slope'], x['global_growth_slope']), axis=1)
category_features['od_risk'] = category_features.apply(
    lambda x: scale_od_risk(x['avg_od_amount'], x['od_slope'], x['od_persistence_ratio']), axis=1)

# ✅ Apply same filters as dealer churn
filtered_category_features = category_features[
    (category_features['sales_yoy_risk'] != 0) &
    (category_features['sales_trend_risk'] != 0) &
    (category_features['regional_risk'] != 0)
].copy()

# ✅ Final score (OD can be NaN)
filtered_category_features['churn_risk_score'] = (
    filtered_category_features['retail_audit_risk'] * 0.20 +
    filtered_category_features['sales_yoy_risk'] * 0.10 +
    filtered_category_features['sales_trend_risk'] * 0.25 +
    filtered_category_features['regional_risk'] * 0.25 +
    filtered_category_features['od_risk'].fillna(0) * 0.20
)

# ✅ Flag churn
filtered_category_features['churn_risk_flag'] = (filtered_category_features['churn_risk_score'] >= risk_threshold).astype(int)

# ✅ Output: high-risk dealer-category pairs
category_churn_output = filtered_category_features[filtered_category_features['churn_risk_flag'] == 1].copy()

print(f"Category-level churn analysis complete: {len(category_churn_output)} at-risk dealer-category pairs.")

display(category_churn_output[['dealer_code', 'category', 'churn_risk_score']].sort_values(by='churn_risk_score', ascending=False).head(10))

