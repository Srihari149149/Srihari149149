import pandas as pd

# Step 1: Load all sheets

file_path = r"C:\Users\P00993489\Downloads\OD weekly data.xlsx"  # replace with your actual path

all_sheets = pd.read_excel(file_path, sheet_name=None)


# Step 2: Combine sheets with sheet name and clean columns

combined = []

for sheet_name, df in all_sheets.items():

    df = df.copy()

    df['sheet_name'] = sheet_name

    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')  # clean names

    df.rename(columns={'customer': 'dealer_code'}, inplace=True)  # match logic

    combined.append(df)

# Step 3: Merge into single DataFrame

od_df = pd.concat(combined, ignore_index=True)

# Step 4: Add numeric week

od_df['week_num'] = od_df['sheet_name'].str.extract(r'(\d+)').astype(int)

# Step 5: Sort properly

od_df = od_df.sort_values(['dealer_code', 'week_num'])

od_df.columns = (
   od_df.columns
   .str.strip()
   .str.lower()
   .str.replace(' ', '_')
   .str.replace('-', '_')
   .str.replace('>', '_over_')  # Optional if your columns use ">"
   .str.replace('.', '')  # remove stray dots if any
)

# Preview


# Step 1: Get full list of dealers and week numbers
all_dealers = od_df['dealer_code'].unique()
all_weeks = sorted(od_df['week_num'].unique())  # Week 1 = most recent
# Step 2: Create full dealer-week frame
full_index = pd.MultiIndex.from_product(
   [all_dealers, all_weeks], names=['dealer_code', 'week_num']
)
full_df = pd.DataFrame(index=full_index).reset_index()
# Step 3: Map correct posting date for each week number
week_dates = od_df[['week_num', 'posting_date']].drop_duplicates()
week_dates = week_dates.groupby('week_num')['posting_date'].first().reset_index()
full_df = full_df.merge(week_dates, on='week_num', how='left')
# Step 4: Merge original OD data
od_complete = pd.merge(full_df, od_df, on=['dealer_code', 'week_num'], how='left', suffixes=('', '_raw'))
# Step 5: Fill OD-related columns with 0 (actual indicators of "no OD")
od_cols = [col for col in od_df.columns if 'over_due' in col or 'od' in col]
od_complete[od_cols] = od_complete[od_cols].fillna(0)
# Step 6: Forward-fill static dealer info like region and other columns
dealer_static_cols = ['sales_office_region', 'unnamed:_3']  # Add more if needed
for col in dealer_static_cols:
   # Create a map of most recent known values per dealer
   latest_info = od_df.dropna(subset=[col]).drop_duplicates('dealer_code', keep='last')[['dealer_code', col]]
   od_complete = od_complete.merge(latest_info, on='dealer_code', how='left', suffixes=('', '_fill'))
   od_complete[col] = od_complete[col].fillna(od_complete[f'{col}_fill'])
   od_complete.drop(columns=[f'{col}_fill'], inplace=True)
# Step 7: Final sort
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])

import numpy as np
# Start with the cleaned dealer-week od_complete DataFrame
# Step 1: Sort properly for rolling calculations
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])
# Step 2: Feature Creation
# 2.1 Average Total OD over last 2 weeks
od_complete['avg_net_over_due_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .rolling(window=2, min_periods=1)
   .mean()
   .reset_index(0, drop=True)
)
# 2.2 Change in OD (delta)
od_complete['delta_od_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .diff(periods=1)
)
# 2.3 Spike flag: 1 if OD went from 0 to > 0
od_complete['spike_flag_last2'] = (
   (od_complete.groupby('dealer_code')['net_over_due'].shift(1) == 0) &
   (od_complete['net_over_due'] > 0)
).astype(int)
# 2.4 Aging ratio: % of OD in old buckets (61+ days)
aging_buckets = ['over_due_61___90', 'over_due_91___180', 'over_due__over__180']
od_complete['aging_od_last_week'] = od_complete[aging_buckets].sum(axis=1)
od_complete['aging_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['aging_od_last_week'] / od_complete['net_over_due'],
   0
)
# 2.5 Clearance ratio: cleared / gross
od_complete['cleared_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['cleared_amount'] / od_complete['net_over_due'],
   0
)
# 2.6 Was dealer in OD last week
od_complete['was_in_od_last_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(-1) > 0
).astype(int)
# 2.7 OD Days in last 3 weeks (no of weeks OD > 0)
# Sort properly
od_complete = od_complete.sort_values(['dealer_code', 'week_num'], ascending=[True, False])
od_complete['od_days_last3w'] = 0

od_complete['od_flag'] = (od_complete['net_over_due'] > 0).astype(int)
for dealer, group in od_complete.groupby('dealer_code'):
    group = group.sort_values('week_num', ascending=True)

    od_days = []

    for idx in range(len(group)):
        future_flags = group['od_flag'].iloc[idx+1 : idx+4]
        od_days.append(future_flags.sum())

    od_complete.loc[group.index, 'od_days_last3w'] = od_days

)
# Step 3: Target Label Creation
# Target = 1 if OD > 0 next week
od_complete['will_go_od_next_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(1) > 0
).astype(int)
# Step 4: Clean final features dataset
feature_cols = [
   'dealer_code', 'week_num', 'posting_date',
   'avg_net_over_due_last2', 'delta_od_last2', 'spike_flag_last2',
   'aging_ratio_last_week', 'cleared_ratio_last_week',
   'was_in_od_last_week', 'od_weeks_last_3w', 'will_go_od_next_week'
]
features_df = od_complete[feature_cols]

# 1. Set Features and Target
feature_cols = [
    'avg_net_over_due_last2', 
    'delta_od_last2', 
    'spike_flag_last2', 
    'aging_ratio_last_week', 
    'cleared_ratio_last_week', 
    'was_in_od_last_week', 
    'od_days_last3w'
]

X = features_df[feature_cols]
y = features_df['will_go_od_next_week']

# 2. Train-Test Split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# 3. Train Decision Tree
from sklearn.tree import DecisionTreeClassifier

dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)
dt_model.fit(X_train, y_train)

# 4. Evaluate Decision Tree
from sklearn.metrics import classification_report, confusion_matrix

y_dt_pred = dt_model.predict(X_test)
print("üìä Decision Tree Report:\n", classification_report(y_test, y_dt_pred))
print("üß© Decision Tree Confusion Matrix:\n", confusion_matrix(y_test, y_dt_pred))

# 5. Train Random Forest
from sklearn.ensemble import RandomForestClassifier

rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf_model.fit(X_train, y_train)

y_rf_pred = rf_model.predict(X_test)
print("üìä Random Forest Report:\n", classification_report(y_test, y_rf_pred))
print("üß© Random Forest Confusion Matrix:\n", confusion_matrix(y_test, y_rf_pred))

# 6. Predict Risk for Entire Data
features_df['od_risk_probability'] = rf_model.predict_proba(X)[:,1]

# 7. Dealers with High OD Risk (>60%)
high_risk_dealers = features_df[features_df['od_risk_probability'] > 0.6]

# 8. Generate Notifications
high_risk_dealers['notification'] = high_risk_dealers.apply(
    lambda x: f"‚ö†Ô∏è Dealer {x['dealer_code']} has a {x['od_risk_probability']*100:.1f}% risk of entering OD next week. Immediate action recommended.",
    axis=1
)

# 9. View or Export Notifications
final_notifications = high_risk_dealers[['dealer_code', 'week_num', 'od_risk_probability', 'notification']]
display(final_notifications)

# (Optional) Export to CSV
# final_notifications.to_csv("OD_Risk_Notifications.csv", index=False)
