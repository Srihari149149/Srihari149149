import pandas as pd

# Step 1: Load all sheets

file_path = r"C:\Users\P00993489\Downloads\OD weekly data.xlsx"  # replace with your actual path

all_sheets = pd.read_excel(file_path, sheet_name=None)


# Step 2: Combine sheets with sheet name and clean columns

combined = []

for sheet_name, df in all_sheets.items():

    df = df.copy()

    df['sheet_name'] = sheet_name

    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')  # clean names

    df.rename(columns={'customer': 'dealer_code'}, inplace=True)  # match logic

    combined.append(df)

# Step 3: Merge into single DataFrame

od_df = pd.concat(combined, ignore_index=True)

# Step 4: Add numeric week

od_df['week_num'] = od_df['sheet_name'].str.extract(r'(\d+)').astype(int)

# Step 5: Sort properly

od_df = od_df.sort_values(['dealer_code', 'week_num'])

od_df.columns = (
   od_df.columns
   .str.strip()
   .str.lower()
   .str.replace(' ', '_')
   .str.replace('-', '_')
   .str.replace('>', '_over_')  # Optional if your columns use ">"
   .str.replace('.', '')  # remove stray dots if any
)

# Preview


# Step 1: Get full list of dealers and week numbers
all_dealers = od_df['dealer_code'].unique()
all_weeks = sorted(od_df['week_num'].unique())  # Week 1 = most recent
# Step 2: Create full dealer-week frame
full_index = pd.MultiIndex.from_product(
   [all_dealers, all_weeks], names=['dealer_code', 'week_num']
)
full_df = pd.DataFrame(index=full_index).reset_index()
# Step 3: Map correct posting date for each week number
week_dates = od_df[['week_num', 'posting_date']].drop_duplicates()
week_dates = week_dates.groupby('week_num')['posting_date'].first().reset_index()
full_df = full_df.merge(week_dates, on='week_num', how='left')
# Step 4: Merge original OD data
od_complete = pd.merge(full_df, od_df, on=['dealer_code', 'week_num'], how='left', suffixes=('', '_raw'))
# Step 5: Fill OD-related columns with 0 (actual indicators of "no OD")
od_cols = [col for col in od_df.columns if 'over_due' in col or 'od' in col]
od_complete[od_cols] = od_complete[od_cols].fillna(0)
# Step 6: Forward-fill static dealer info like region and other columns
dealer_static_cols = ['sales_office_region', 'unnamed:_3']  # Add more if needed
for col in dealer_static_cols:
   # Create a map of most recent known values per dealer
   latest_info = od_df.dropna(subset=[col]).drop_duplicates('dealer_code', keep='last')[['dealer_code', col]]
   od_complete = od_complete.merge(latest_info, on='dealer_code', how='left', suffixes=('', '_fill'))
   od_complete[col] = od_complete[col].fillna(od_complete[f'{col}_fill'])
   od_complete.drop(columns=[f'{col}_fill'], inplace=True)
# Step 7: Final sort
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])

import numpy as np
# Start with the cleaned dealer-week od_complete DataFrame
# Step 1: Sort properly for rolling calculations
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])
# Step 2: Feature Creation
# 2.1 Average Total OD over last 2 weeks
od_complete['avg_net_over_due_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .rolling(window=2, min_periods=1)
   .mean()
   .reset_index(0, drop=True)
)
# 2.2 Change in OD (delta)
od_complete['delta_od_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .diff(periods=1)
)
# 2.3 Spike flag: 1 if OD went from 0 to > 0
od_complete['spike_flag_last2'] = (
   (od_complete.groupby('dealer_code')['net_over_due'].shift(1) == 0) &
   (od_complete['net_over_due'] > 0)
).astype(int)
# 2.4 Aging ratio: % of OD in old buckets (61+ days)
aging_buckets = ['over_due_61___90', 'over_due_91___180', 'over_due__over__180']
od_complete['aging_od_last_week'] = od_complete[aging_buckets].sum(axis=1)
od_complete['aging_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['aging_od_last_week'] / od_complete['net_over_due'],
   0
)
# 2.5 Clearance ratio: cleared / gross
od_complete['cleared_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['cleared_amount'] / od_complete['net_over_due'],
   0
)
# 2.6 Was dealer in OD last week
od_complete['was_in_od_last_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(-1) > 0
).astype(int)
# 2.7 OD Days in last 3 weeks (no of weeks OD > 0)
# Sort properly
od_complete = od_complete.sort_values(['dealer_code', 'week_num'], ascending=[True, False])
od_complete['od_days_last3w'] = 0

od_complete['od_flag'] = (od_complete['net_over_due'] > 0).astype(int)
for dealer, group in od_complete.groupby('dealer_code'):
    group = group.sort_values('week_num', ascending=True)

    od_days = []

    for idx in range(len(group)):
        future_flags = group['od_flag'].iloc[idx+1 : idx+4]
        od_days.append(future_flags.sum())

    od_complete.loc[group.index, 'od_days_last3w'] = od_days

)
# Step 3: Target Label Creation
# Target = 1 if OD > 0 next week
od_complete['will_go_od_next_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(1) > 0
).astype(int)
# Step 4: Clean final features dataset
feature_cols = [
   'dealer_code', 'week_num', 'posting_date',
   'avg_net_over_due_last2', 'delta_od_last2', 'spike_flag_last2',
   'aging_ratio_last_week', 'cleared_ratio_last_week',
   'was_in_od_last_week', 'od_weeks_last_3w', 'will_go_od_next_week'
]
features_df = od_complete[feature_cols]

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# --- Assuming your cleaned data is already in `od_complete` ---

# Step 1: Summarize dealer-level features (past 8 weeks)

dealer_summary = od_complete.groupby('dealer_code').agg({
    'net_over_due': ['mean', 'max', 'min', 'std'],
    'od_flag': 'sum',
    'aging_ratio_last_week': 'mean',
    'cleared_ratio_last_week': 'mean',
    'delta_od_last2': ['mean', 'sum'],
    'spike_flag_last2': 'sum',
    'was_in_od_last_week': 'max'  # 1 if OD in latest week
})

# Flatten multi-index columns
dealer_summary.columns = ['_'.join(col).strip() for col in dealer_summary.columns.values]
dealer_summary = dealer_summary.reset_index()

# Step 2: Create Target Variable

# Target: Will the dealer go into OD next week?
# Logic: If dealer had OD in Week 1 (latest week), assume next week also risky
latest_week = 1  # Week 1 is latest
latest_week_df = od_complete[od_complete['week_num'] == latest_week][['dealer_code', 'net_over_due']]

dealer_summary = dealer_summary.merge(latest_week_df, on='dealer_code', how='left')

dealer_summary['will_go_od_next_week'] = (dealer_summary['net_over_due'] > 0).astype(int)

# Drop extra net_over_due
dealer_summary = dealer_summary.drop(columns=['net_over_due'])

# Step 3: Prepare X and y
feature_cols = [col for col in dealer_summary.columns if col not in ['dealer_code', 'will_go_od_next_week']]

X = dealer_summary[feature_cols]
y = dealer_summary['will_go_od_next_week']

# Step 4: Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Step 5: Train Random Forest
rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf_model.fit(X_train, y_train)

# Step 6: Evaluate Model
y_rf_pred = rf_model.predict(X_test)

print("üìä Random Forest Report:\n", classification_report(y_test, y_rf_pred))
print("üß© Random Forest Confusion Matrix:\n", confusion_matrix(y_test, y_rf_pred))

# Step 7: Predict Risk for Full Dealer List
dealer_summary['od_risk_probability'] = rf_model.predict_proba(X)[:,1]

# Step 8: Generate Notification Only for High Risk Dealers (optional threshold 60%)
high_risk_dealers = dealer_summary[dealer_summary['od_risk_probability'] > 0.6]

high_risk_dealers['notification'] = high_risk_dealers.apply(
    lambda x: f"‚ö†Ô∏è Dealer {x['dealer_code']} has a {x['od_risk_probability']*100:.1f}% risk of entering OD next week. Please intervene immediately.",
    axis=1
)

# Step 9: View/Export
final_notifications = high_risk_dealers[['dealer_code', 'od_risk_probability', 'notification']]
display(final_notifications)

# (Optional) Export to CSV
# final_notifications.to_csv("Final_OD_Risk_Predictions.csv", index=False)
