import pandas as pd

# Step 1: Load all sheets

file_path = r"C:\Users\P00993489\Downloads\OD weekly data.xlsx"  # replace with your actual path

all_sheets = pd.read_excel(file_path, sheet_name=None)


# Step 2: Combine sheets with sheet name and clean columns

combined = []

for sheet_name, df in all_sheets.items():

    df = df.copy()

    df['sheet_name'] = sheet_name

    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')  # clean names

    df.rename(columns={'customer': 'dealer_code'}, inplace=True)  # match logic

    combined.append(df)

# Step 3: Merge into single DataFrame

od_df = pd.concat(combined, ignore_index=True)

# Step 4: Add numeric week

od_df['week_num'] = od_df['sheet_name'].str.extract(r'(\d+)').astype(int)

# Step 5: Sort properly

od_df = od_df.sort_values(['dealer_code', 'week_num'])

od_df.columns = (
   od_df.columns
   .str.strip()
   .str.lower()
   .str.replace(' ', '_')
   .str.replace('-', '_')
   .str.replace('>', '_over_')  # Optional if your columns use ">"
   .str.replace('.', '')  # remove stray dots if any
)

# Preview


# Step 1: Get full list of dealers and week numbers
all_dealers = od_df['dealer_code'].unique()
all_weeks = sorted(od_df['week_num'].unique())  # Week 1 = most recent
# Step 2: Create full dealer-week frame
full_index = pd.MultiIndex.from_product(
   [all_dealers, all_weeks], names=['dealer_code', 'week_num']
)
full_df = pd.DataFrame(index=full_index).reset_index()
# Step 3: Map correct posting date for each week number
week_dates = od_df[['week_num', 'posting_date']].drop_duplicates()
week_dates = week_dates.groupby('week_num')['posting_date'].first().reset_index()
full_df = full_df.merge(week_dates, on='week_num', how='left')
# Step 4: Merge original OD data
od_complete = pd.merge(full_df, od_df, on=['dealer_code', 'week_num'], how='left', suffixes=('', '_raw'))
# Step 5: Fill OD-related columns with 0 (actual indicators of "no OD")
od_cols = [col for col in od_df.columns if 'over_due' in col or 'od' in col]
od_complete[od_cols] = od_complete[od_cols].fillna(0)
# Step 6: Forward-fill static dealer info like region and other columns
dealer_static_cols = ['sales_office_region', 'unnamed:_3']  # Add more if needed
for col in dealer_static_cols:
   # Create a map of most recent known values per dealer
   latest_info = od_df.dropna(subset=[col]).drop_duplicates('dealer_code', keep='last')[['dealer_code', col]]
   od_complete = od_complete.merge(latest_info, on='dealer_code', how='left', suffixes=('', '_fill'))
   od_complete[col] = od_complete[col].fillna(od_complete[f'{col}_fill'])
   od_complete.drop(columns=[f'{col}_fill'], inplace=True)
# Step 7: Final sort
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])

import numpy as np
# Start with the cleaned dealer-week od_complete DataFrame
# Step 1: Sort properly for rolling calculations
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])
# Step 2: Feature Creation
# 2.1 Average Total OD over last 2 weeks
od_complete['avg_net_over_due_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .rolling(window=2, min_periods=1)
   .mean()
   .reset_index(0, drop=True)
)
# 2.2 Change in OD (delta)
od_complete['delta_od_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .diff(periods=1)
)
# 2.3 Spike flag: 1 if OD went from 0 to > 0
od_complete['spike_flag_last2'] = (
   (od_complete.groupby('dealer_code')['net_over_due'].shift(1) == 0) &
   (od_complete['net_over_due'] > 0)
).astype(int)
# 2.4 Aging ratio: % of OD in old buckets (61+ days)
aging_buckets = ['over_due_61___90', 'over_due_91___180', 'over_due__over__180']
od_complete['aging_od_last_week'] = od_complete[aging_buckets].sum(axis=1)
od_complete['aging_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['aging_od_last_week'] / od_complete['net_over_due'],
   0
)
# 2.5 Clearance ratio: cleared / gross
od_complete['cleared_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['cleared_amount'] / od_complete['net_over_due'],
   0
)
# 2.6 Was dealer in OD last week
od_complete['was_in_od_last_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(-1) > 0
).astype(int)
# 2.7 OD Days in last 3 weeks (no of weeks OD > 0)
# Sort properly
od_complete = od_complete.sort_values(['dealer_code', 'week_num'], ascending=[True, False])
od_complete['od_days_last3w'] = 0

od_complete['od_flag'] = (od_complete['net_over_due'] > 0).astype(int)
for dealer, group in od_complete.groupby('dealer_code'):
    group = group.sort_values('week_num', ascending=True)

    od_days = []

    for idx in range(len(group)):
        future_flags = group['od_flag'].iloc[idx+1 : idx+4]
        od_days.append(future_flags.sum())

    od_complete.loc[group.index, 'od_days_last3w'] = od_days

)
# Step 3: Target Label Creation
# Target = 1 if OD > 0 next week
od_complete['will_go_od_next_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(1) > 0
).astype(int)
# Step 4: Clean final features dataset
feature_cols = [
   'dealer_code', 'week_num', 'posting_date',
   'avg_net_over_due_last2', 'delta_od_last2', 'spike_flag_last2',
   'aging_ratio_last_week', 'cleared_ratio_last_week',
   'was_in_od_last_week', 'od_weeks_last_3w', 'will_go_od_next_week'
]
features_df = od_complete[feature_cols]

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# --- Assuming your 'od_complete' DataFrame is already ready and cleaned ---

# Step 1: Pick clean dealers (OD=0 for Week 2, 3 and 4)

weeks_to_check = [2, 3, 4]

# Filter relevant weeks
clean_weeks_df = od_complete[od_complete['week_num'].isin(weeks_to_check)]

# Group by dealer and sum Net Over Due
dealer_zero_od = (
    clean_weeks_df
    .groupby('dealer_code')['net_over_due']
    .sum()
    .reset_index()
)

# Select dealers where total OD=0 across weeks 2,3,4
clean_dealers_list = dealer_zero_od[dealer_zero_od['net_over_due'] == 0]['dealer_code'].unique()

print(f"‚úÖ {len(clean_dealers_list)} clean dealers found with OD=0 across weeks 2,3,4")

# Step 2: Filter full OD data to only these dealers
od_complete_clean = od_complete[od_complete['dealer_code'].isin(clean_dealers_list)]

# Step 3: Summarize behavior for weeks 8‚Äì2
past_weeks_df = od_complete_clean[(od_complete_clean['week_num'] >= 2) & (od_complete_clean['week_num'] <= 8)]

dealer_summary_past = past_weeks_df.groupby('dealer_code').agg({
    'net_over_due': ['mean', 'max', 'min', 'std'],
    'od_flag': 'sum',
    'aging_ratio_last_week': 'mean',
    'cleared_ratio_last_week': 'mean',
    'spike_flag_last2': 'sum'
})

# Flatten multi-index
dealer_summary_past.columns = ['_'.join(col).strip() for col in dealer_summary_past.columns.values]
dealer_summary_past = dealer_summary_past.reset_index()

# Remove dealers who were completely absent in past weeks
dealer_summary_past = dealer_summary_past[
    ~(
        (dealer_summary_past['net_over_due_mean'] == 0) & 
        (dealer_summary_past['net_over_due_max'] == 0) & 
        (dealer_summary_past['net_over_due_min'] == 0)
    )
]

print(f"‚úÖ After removing blank dealers, {dealer_summary_past.shape[0]} dealers remain.")

# Step 4: Get Target from Week 1 OD
week1_df = od_complete[od_complete['week_num'] == 1][['dealer_code', 'net_over_due']]
week1_df['will_go_od_next_week'] = (week1_df['net_over_due'] > 0).astype(int)

# Merge features with Week 1 OD
dealer_final = dealer_summary_past.merge(week1_df[['dealer_code', 'will_go_od_next_week']], on='dealer_code', how='inner')

# Step 5: Define X and y
X = dealer_final.drop(columns=['dealer_code', 'will_go_od_next_week'])
y = dealer_final['will_go_od_next_week']

# Step 6: Random Forest Model with Class Balance and Controlled Overfitting
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=5,
    class_weight='balanced',
    max_features='sqrt',        # Reduce overfitting
    min_samples_leaf=5,         # Prevent tiny overfit trees
    random_state=42
)

# Step 7: Cross Validation
cv_scores = cross_val_score(rf_model, X, y, cv=3, scoring='f1')  # F1 score due to imbalance
print(f"üìà 3-Fold Cross Validation F1 Scores: {cv_scores}")
print(f"üìä Average F1 Score: {np.mean(cv_scores):.3f}")

# Step 8: Train model on full data
rf_model.fit(X, y)

# Step 9: Predict back on X
y_pred = rf_model.predict(X)

# Step 10: Evaluation
print("\nüìú Final Classification Report (Backtest):")
print(classification_report(y, y_pred))
print("üß© Final Confusion Matrix:")
print(confusion_matrix(y, y_pred))

# Step 11: Predict Risk Probabilities
dealer_final['od_risk_probability'] = rf_model.predict_proba(X)[:,1]

# Step 12: Generate Notifications for High Risk Dealers
high_risk_dealers = dealer_final[dealer_final['od_risk_probability'] > 0.6]

high_risk_dealers['notification'] = high_risk_dealers.apply(
    lambda x: f"‚ö†Ô∏è Dealer {x['dealer_code']} has a {x['od_risk_probability']*100:.1f}% predicted risk of entering OD next week based on past stable behavior.",
    axis=1
)

# Step 13: View or Export
final_notifications = high_risk_dealers[['dealer_code', 'od_risk_probability', 'notification']]
display(final_notifications)

# Optional: Save
# final_notifications.to_csv("Final_OD_Risk_Predictions_Clean.csv", index=False)

