import pandas as pd

# Step 1: Load all sheets

file_path = r"C:\Users\P00993489\Downloads\OD weekly data.xlsx"  # replace with your actual path

all_sheets = pd.read_excel(file_path, sheet_name=None)


# Step 2: Combine sheets with sheet name and clean columns

combined = []

for sheet_name, df in all_sheets.items():

    df = df.copy()

    df['sheet_name'] = sheet_name

    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')  # clean names

    df.rename(columns={'customer': 'dealer_code'}, inplace=True)  # match logic

    combined.append(df)

# Step 3: Merge into single DataFrame

od_df = pd.concat(combined, ignore_index=True)

# Step 4: Add numeric week

od_df['week_num'] = od_df['sheet_name'].str.extract(r'(\d+)').astype(int)

# Step 5: Sort properly

od_df = od_df.sort_values(['dealer_code', 'week_num'])

od_df.columns = (
   od_df.columns
   .str.strip()
   .str.lower()
   .str.replace(' ', '_')
   .str.replace('-', '_')
   .str.replace('>', '_over_')  # Optional if your columns use ">"
   .str.replace('.', '')  # remove stray dots if any
)

# Preview


# Step 1: Get full list of dealers and week numbers
all_dealers = od_df['dealer_code'].unique()
all_weeks = sorted(od_df['week_num'].unique())  # Week 1 = most recent
# Step 2: Create full dealer-week frame
full_index = pd.MultiIndex.from_product(
   [all_dealers, all_weeks], names=['dealer_code', 'week_num']
)
full_df = pd.DataFrame(index=full_index).reset_index()
# Step 3: Map correct posting date for each week number
week_dates = od_df[['week_num', 'posting_date']].drop_duplicates()
week_dates = week_dates.groupby('week_num')['posting_date'].first().reset_index()
full_df = full_df.merge(week_dates, on='week_num', how='left')
# Step 4: Merge original OD data
od_complete = pd.merge(full_df, od_df, on=['dealer_code', 'week_num'], how='left', suffixes=('', '_raw'))
# Step 5: Fill OD-related columns with 0 (actual indicators of "no OD")
od_cols = [col for col in od_df.columns if 'over_due' in col or 'od' in col]
od_complete[od_cols] = od_complete[od_cols].fillna(0)
# Step 6: Forward-fill static dealer info like region and other columns
dealer_static_cols = ['sales_office_region', 'unnamed:_3']  # Add more if needed
for col in dealer_static_cols:
   # Create a map of most recent known values per dealer
   latest_info = od_df.dropna(subset=[col]).drop_duplicates('dealer_code', keep='last')[['dealer_code', col]]
   od_complete = od_complete.merge(latest_info, on='dealer_code', how='left', suffixes=('', '_fill'))
   od_complete[col] = od_complete[col].fillna(od_complete[f'{col}_fill'])
   od_complete.drop(columns=[f'{col}_fill'], inplace=True)
# Step 7: Final sort
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])

import numpy as np
# Start with the cleaned dealer-week od_complete DataFrame
# Step 1: Sort properly for rolling calculations
od_complete = od_complete.sort_values(['dealer_code', 'week_num'])
# Step 2: Feature Creation
# 2.1 Average Total OD over last 2 weeks
od_complete['avg_net_over_due_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .rolling(window=2, min_periods=1)
   .mean()
   .reset_index(0, drop=True)
)
# 2.2 Change in OD (delta)
od_complete['delta_od_last2'] = (
   od_complete
   .groupby('dealer_code')['net_over_due']
   .diff(periods=1)
)
# 2.3 Spike flag: 1 if OD went from 0 to > 0
od_complete['spike_flag_last2'] = (
   (od_complete.groupby('dealer_code')['net_over_due'].shift(1) == 0) &
   (od_complete['net_over_due'] > 0)
).astype(int)
# 2.4 Aging ratio: % of OD in old buckets (61+ days)
aging_buckets = ['over_due_61___90', 'over_due_91___180', 'over_due__over__180']
od_complete['aging_od_last_week'] = od_complete[aging_buckets].sum(axis=1)
od_complete['aging_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['aging_od_last_week'] / od_complete['net_over_due'],
   0
)
# 2.5 Clearance ratio: cleared / gross
od_complete['cleared_ratio_last_week'] = np.where(
   od_complete['net_over_due'] > 0,
   od_complete['cleared_amount'] / od_complete['net_over_due'],
   0
)
# 2.6 Was dealer in OD last week
od_complete['was_in_od_last_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(-1) > 0
).astype(int)
# 2.7 OD Days in last 3 weeks (no of weeks OD > 0)
# Sort properly
od_complete = od_complete.sort_values(['dealer_code', 'week_num'], ascending=[True, False])
od_complete['od_days_last3w'] = 0

od_complete['od_flag'] = (od_complete['net_over_due'] > 0).astype(int)
for dealer, group in od_complete.groupby('dealer_code'):
    group = group.sort_values('week_num', ascending=True)

    od_days = []

    for idx in range(len(group)):
        future_flags = group['od_flag'].iloc[idx+1 : idx+4]
        od_days.append(future_flags.sum())

    od_complete.loc[group.index, 'od_days_last3w'] = od_days

)
# Step 3: Target Label Creation
# Target = 1 if OD > 0 next week
od_complete['will_go_od_next_week'] = (
   od_complete.groupby('dealer_code')['net_over_due'].shift(1) > 0
).astype(int)
# Step 4: Clean final features dataset
feature_cols = [
   'dealer_code', 'week_num', 'posting_date',
   'avg_net_over_due_last2', 'delta_od_last2', 'spike_flag_last2',
   'aging_ratio_last_week', 'cleared_ratio_last_week',
   'was_in_od_last_week', 'od_weeks_last_3w', 'will_go_od_next_week'
]
features_df = od_complete[feature_cols]

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# --- Assuming your cleaned data is already in `od_complete` ---

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt

# --- Assuming your cleaned full od_complete is ready ---

# Step 1: Filter Dealers Who Had Net OD = 0 in Week 1
week1_df = od_complete[od_complete['week_num'] == 1]
clean_dealers_list = week1_df[week1_df['net_over_due'] == 0]['dealer_code'].unique()

# Step 2: Filter main dataset only for these clean dealers
od_complete_clean = od_complete[od_complete['dealer_code'].isin(clean_dealers_list)]

# Step 3: Summarize dealer behavior over last 8 weeks
dealer_summary = od_complete_clean.groupby('dealer_code').agg({
    'net_over_due': ['mean', 'max', 'min', 'std'],
    'od_flag': 'sum',
    'aging_ratio_last_week': 'mean',
    'cleared_ratio_last_week': 'mean',
    'delta_od_last2': ['mean', 'sum'],
    'spike_flag_last2': 'sum',
    'was_in_od_last_week': 'max'
})

# Step 4: Flatten multi-index columns
dealer_summary.columns = ['_'.join(col).strip() for col in dealer_summary.columns.values]
dealer_summary = dealer_summary.reset_index()

# Step 5: Target Variable: Did dealer enter OD in Week 0 (future week)?
# You don't have future week 0 data â€” 
# so assume target as 0 for now (this will be future prediction)

dealer_summary['will_go_od_next_week'] = 0  # placeholder

# Step 6: Prepare X (no y for now because prediction will be based on risk probability)

feature_cols = [col for col in dealer_summary.columns if col not in ['dealer_code', 'will_go_od_next_week']]

X = dealer_summary[feature_cols]

# Step 7: Train Random Forest (Train on past data if available â€” right now placeholder)
rf_model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
# rf_model.fit(X_train, y_train)  # not possible without real labels here

# ðŸ‘‰ Instead, if you already trained a model before using older data, use that model here!

# Step 8: Predict OD Risk Probabilities
# Placeholder until model trained properly

# Step 9: Final Output Dealers Ready
dealer_summary['predicted_od_risk'] = np.nan  # for now no prediction

# Step 10: Display
display(dealer_summary)
